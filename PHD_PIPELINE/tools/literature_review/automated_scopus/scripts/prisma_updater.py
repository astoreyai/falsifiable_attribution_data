#!/usr/bin/env python3
"""
PRISMA Diagram Updater

Purpose: Automatically update PRISMA flow diagram with search results
Author: PhD Pipeline Automated Tools
Date: October 2025

Usage:
    python prisma_updater.py           # Update PRISMA diagram
    python prisma_updater.py --report  # Generate PRISMA report
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import yaml


class PRISMAUpdater:
    """Update PRISMA flow diagram with search results"""

    def __init__(self, config_path: str = "../config/scopus_config.yaml"):
        """Initialize updater with configuration"""
        self.config = self._load_config(config_path)
        self.setup_logging()

    def _load_config(self, config_path: str) -> Dict:
        """Load configuration from YAML file"""
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)

    def setup_logging(self):
        """Setup logging"""
        logging.basicConfig(
            level=logging.INFO,
            format='[%(asctime)s] %(levelname)s: %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        self.logger = logging.getLogger('PRISMAUpdater')

    def load_search_results(self, results_dir: str = "../results") -> List[Dict]:
        """Load all result JSON files"""
        results_path = Path(results_dir)

        if not results_path.exists():
            self.logger.error(f"Results directory not found: {results_dir}")
            return []

        json_files = sorted(results_path.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)

        if not json_files:
            self.logger.error("No result files found")
            return []

        all_results = []
        for json_file in json_files:
            with open(json_file, 'r') as f:
                data = json.load(f)
                all_results.append(data)

        return all_results

    def load_deduplication_report(self, reports_dir: str = "../reports") -> Dict:
        """Load most recent deduplication report"""
        reports_path = Path(reports_dir)

        if not reports_path.exists():
            return {}

        # Find most recent deduplication report
        report_files = sorted(reports_path.glob("deduplication_report_*.md"),
                              key=lambda p: p.stat().st_mtime, reverse=True)

        if not report_files:
            return {}

        # Parse report to extract numbers (simple parsing)
        report_file = report_files[0]
        dedupe_stats = {}

        with open(report_file, 'r') as f:
            content = f.read()

            # Extract key numbers
            import re
            original_match = re.search(r'\*\*Original Papers:\*\* (\d+)', content)
            duplicates_match = re.search(r'\*\*Duplicates Found:\*\* (\d+)', content)
            unique_match = re.search(r'\*\*Unique Papers:\*\* (\d+)', content)

            if original_match:
                dedupe_stats['original'] = int(original_match.group(1))
            if duplicates_match:
                dedupe_stats['duplicates'] = int(duplicates_match.group(1))
            if unique_match:
                dedupe_stats['unique'] = int(unique_match.group(1))

        return dedupe_stats

    def generate_prisma_content(self, results: List[Dict], dedupe_stats: Dict) -> str:
        """Generate PRISMA diagram content"""
        # Calculate totals
        total_results = sum(r['execution']['total_results'] for r in results)

        # Deduplication stats
        duplicates_removed = dedupe_stats.get('duplicates', 0)
        records_after_dedupe = dedupe_stats.get('unique', total_results)

        # Generate PRISMA markdown
        content = f"""# PRISMA Flow Diagram

**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Auto-generated by:** Automated Scopus Pipeline

---

## Identification

**Records identified from Scopus:**
"""

        # List each search
        for result in results:
            query = result['query']
            count = result['execution']['total_results']
            timestamp = result['execution']['timestamp']
            content += f"- {query['name']} (`{query['id']}`): {count} records (searched: {timestamp[:10]})\n"

        content += f"\n**Total records identified:** {total_results}\n\n"

        content += """**Records identified from other sources:**
- Citation searching: *[To be filled after manual citation search]*
- Hand searching: *[To be filled if applicable]*

"""

        content += f"""---

## Screening

**Duplicates removed:** {duplicates_removed}

**Records screened (title/abstract):** {records_after_dedupe}

**Records excluded at title/abstract screening:** *[To be filled after manual screening]*

**Records sought for full-text retrieval:** *[To be filled after abstract screening]*

**Records not retrieved:** *[To be filled if papers are inaccessible]*

---

## Eligibility

**Full-text articles assessed for eligibility:** *[To be filled after retrieving full texts]*

**Full-text articles excluded with reasons:** *[To be filled after full-text screening]*
- Reason 1: [count]
- Reason 2: [count]
- Reason 3: [count]

---

## Included

**Studies included in review:** *[To be filled after all screening complete]*

**Studies included in synthesis/analysis:** *[To be filled - may be same as above]*

---

## PRISMA Diagram (Text Format)

```
┌──────────────────────────────────────────────────────────────┐
│                      IDENTIFICATION                           │
├──────────────────────────────────────────────────────────────┤
│  Records from Scopus: {total_results}                                │
│  Records from other sources: [TBD]                           │
│                                                              │
│  Total records identified: {total_results}                           │
└────────────────────────┬─────────────────────────────────────┘
                         │
                         ▼
┌──────────────────────────────────────────────────────────────┐
│                       SCREENING                              │
├──────────────────────────────────────────────────────────────┤
│  Duplicates removed: {duplicates_removed}                                 │
│                                                              │
│  Records screened: {records_after_dedupe}                                │
│  ├─► Excluded (title/abstract): [TBD]                       │
│  │                                                           │
│  └─► Records for full-text retrieval: [TBD]                 │
└────────────────────────┬─────────────────────────────────────┘
                         │
                         ▼
┌──────────────────────────────────────────────────────────────┐
│                      ELIGIBILITY                             │
├──────────────────────────────────────────────────────────────┤
│  Full-text articles assessed: [TBD]                         │
│  ├─► Excluded (with reasons): [TBD]                          │
│  │                                                           │
│  └─► Articles not retrieved: [TBD]                           │
└────────────────────────┬─────────────────────────────────────┘
                         │
                         ▼
┌──────────────────────────────────────────────────────────────┐
│                        INCLUDED                              │
├──────────────────────────────────────────────────────────────┤
│  Studies included in review: [TBD]                          │
│  Studies included in synthesis: [TBD]                       │
└──────────────────────────────────────────────────────────────┘
```

---

## Search Provenance

**Search Execution Details:**

"""

        # Add provenance for each search
        for result in results:
            query = result['query']
            exec_info = result['execution']

            content += f"""### {query['name']} (`{query['id']}`)

- **Query:**
  ```
  {query['query']}
  ```
- **Date Range:** {query.get('date_range', {}).get('start', 'N/A')} - {query.get('date_range', {}).get('end', 'N/A')}
- **Subject Areas:** {', '.join(query.get('subject_areas', [])) or 'N/A'}
- **Document Types:** {', '.join(query.get('document_types', [])) or 'N/A'}
- **Execution Date:** {exec_info['timestamp']}
- **Results:** {exec_info['total_results']} papers
- **API Calls:** {exec_info['api_calls']}

"""

        content += """---

## Notes

- This PRISMA diagram is automatically updated from Scopus search results
- Manual screening phases (title/abstract, full-text) must be updated manually
- Citation searching and hand searching must be documented separately
- All search queries are version-controlled in `config/search_queries.yaml`
- Complete reproducibility: execute `python scopus_search.py` with same config

---

**For publication:** Generate visual PRISMA diagram using:
- PRISMA Flow Diagram Generator: http://prisma.thetacollaborative.ca/
- Or use LaTeX/TikZ template from `templates/`

"""

        return content

    def update_prisma_file(self, results: List[Dict], dedupe_stats: Dict,
                            output_path: str = "../prisma_flow_diagram.md"):
        """Update PRISMA diagram file"""
        content = self.generate_prisma_content(results, dedupe_stats)

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w') as f:
            f.write(content)

        self.logger.info(f"PRISMA diagram updated: {output_file}")

    def generate_prisma_report(self, results: List[Dict], dedupe_stats: Dict,
                                reports_dir: str = "../reports"):
        """Generate PRISMA summary report"""
        reports_path = Path(reports_dir)
        reports_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d")
        report_path = reports_path / f"prisma_report_{timestamp}.md"

        total_results = sum(r['execution']['total_results'] for r in results)
        duplicates = dedupe_stats.get('duplicates', 0)
        unique = dedupe_stats.get('unique', total_results)

        with open(report_path, 'w') as f:
            f.write("# PRISMA Report\n\n")
            f.write(f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")

            f.write("## Current Status\n\n")
            f.write(f"- **Searches Executed:** {len(results)}\n")
            f.write(f"- **Records Identified:** {total_results}\n")
            f.write(f"- **Duplicates Removed:** {duplicates}\n")
            f.write(f"- **Records After Deduplication:** {unique}\n\n")

            f.write("## Completion Status\n\n")
            f.write("- [x] Database searches executed\n")
            f.write("- [x] Deduplication completed\n")
            f.write("- [ ] Title/abstract screening\n")
            f.write("- [ ] Full-text screening\n")
            f.write("- [ ] Citation network search\n")
            f.write("- [ ] Data extraction\n")
            f.write("- [ ] Synthesis\n\n")

            f.write("## Next Steps\n\n")
            f.write("1. Begin title/abstract screening\n")
            f.write("2. Update PRISMA diagram with screening results\n")
            f.write("3. Proceed to full-text screening\n")
            f.write("4. Conduct citation network search\n")
            f.write("5. Finalize PRISMA diagram for publication\n\n")

        self.logger.info(f"PRISMA report saved to: {report_path}")


def main():
    """Main execution function"""
    parser = argparse.ArgumentParser(description="Update PRISMA flow diagram")
    parser.add_argument('--report', action='store_true', help='Generate PRISMA report')
    parser.add_argument('--config', type=str, default='../config/scopus_config.yaml', help='Path to config file')
    parser.add_argument('--output', type=str, default='../prisma_flow_diagram.md', help='Output PRISMA file path')

    args = parser.parse_args()

    # Initialize updater
    updater = PRISMAUpdater(config_path=args.config)

    print("=" * 60)
    print("PRISMA Diagram Updater")
    print("=" * 60)

    # Load search results
    results = updater.load_search_results()

    if not results:
        print("❌ No search results found")
        return 1

    # Load deduplication stats
    dedupe_stats = updater.load_deduplication_report()

    if not dedupe_stats:
        print("⚠️  No deduplication report found - using raw counts")
        dedupe_stats = {}

    # Update PRISMA diagram
    updater.update_prisma_file(results, dedupe_stats, output_path=args.output)

    # Generate report if requested
    if args.report:
        updater.generate_prisma_report(results, dedupe_stats)

    # Summary
    total_results = sum(r['execution']['total_results'] for r in results)
    duplicates = dedupe_stats.get('duplicates', 0)
    unique = dedupe_stats.get('unique', total_results)

    print("=" * 60)
    print("✅ PRISMA diagram updated!")
    print(f"\nRecords identified: {total_results}")
    print(f"Duplicates removed: {duplicates}")
    print(f"Records after deduplication: {unique}")
    print(f"\nPRISMA file: {args.output}")
    print("=" * 60)

    return 0


if __name__ == '__main__':
    sys.exit(main())
